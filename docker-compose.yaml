services:

  de_psql:
    image: postgres:15
    container_name: de_psql
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow 
      - POSTGRES_DB=airflow
    volumes:
      - ./mnt/postgresql:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always
    networks:
      - de_network

  minio:
    hostname: minio
    image: "minio/minio"
    container_name: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command:
      - server
      - /data
      - --console-address
      - ":9001"
    volumes:
      - ./mnt/minio:/data
    env_file:
      - env
    networks:
      - de_network

  mc:
    image: minio/mc
    container_name: mc
    hostname: mc
    env_file:
      - env
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc config host add minio http://minio:9000 minio minio123)
      do
        echo '...waiting...' && sleep 1;
      done;
      /usr/bin/mc mb minio/warehouse;
      /usr/bin/mc policy set public minio/warehouse;
      exit 0;
      "
    depends_on:
      - minio
    networks:
      - de_network

  # de_streamlit:
  #   build:
  #     context: ./docker_images/streamlit
  #     dockerfile: ./Dockerfile
  #   image: de_streamlit:latest
  #   container_name: de_streamlit
  #   volumes:
  #     - ./docker_images/streamlit/app:/app
  #   ports:
  #     - "8501:8501"
  #   networks:
  #     - de_network

  redis:
    image: redis:latest
    container_name: airflow_redis
    restart: always
    ports:
      - "6379:6379"
    networks:
      - de_network

  airflow_init:
    # image: apache/airflow:2.7.0
    build: 
      context: .
      dockerfile: docker/airflow/Dockerfile
    container_name: airflow_init
    depends_on:
      - de_psql
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@de_psql:5432/airflow
    command: >
      bash -c "
      airflow db init &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com
      "
    networks:
      - de_network

  airflow_webserver:
    # image: apache/airflow:2.7.0
    build:
      context: .
      dockerfile: docker/airflow/Dockerfile
    container_name: airflow_webserver
    restart: always
    depends_on:
      airflow_init:
        condition: service_completed_successfully
      de_psql:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@de_psql:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@de_psql:5432/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: mysecretkey
      PYSPARK_PYTHON: /usr/local/bin/python
    ports:
      - "8080:8080"
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
      - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
      - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
      - ${AIRFLOW_PROJ_DIR:-.}/config:/opt/airflow/config
      - ${AIRFLOW_PROJ_DIR:-.}/src:/opt/airflow/src
      - ${AIRFLOW_PROJ_DIR:-.}/requirements.txt:/opt/airflow/requirements.txt
    command: bash -c "pip install -r /opt/airflow/requirements.txt && airflow webserver"
    networks:
      - de_network

  airflow_scheduler:
    # image: apache/airflow:2.7.0
    build:
      context: .
      dockerfile: docker/airflow/Dockerfile
    container_name: airflow_scheduler
    restart: always
    depends_on:
      - airflow_webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@de_psql:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@de_psql:5432/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: mysecretkey
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
      - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
      - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
      - ${AIRFLOW_PROJ_DIR:-.}/config:/opt/airflow/config
      - ${AIRFLOW_PROJ_DIR:-.}/src:/opt/airflow/src
      - ${AIRFLOW_PROJ_DIR:-.}/requirements.txt:/opt/airflow/requirements.txt
    command: bash -c "pip install -r /opt/airflow/requirements.txt && airflow scheduler"
    networks:
      - de_network

  airflow_worker:
    # image: apache/airflow:2.7.0
    build:
      context: .
      dockerfile: docker/airflow/Dockerfile
    container_name: airflow_worker
    restart: always
    depends_on:
      - airflow_webserver
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@de_psql:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@de_psql:5432/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: mysecretkey
      PYSPARK_PYTHON: /usr/local/bin/python
      MINIO_ENDPOINT: http://minio:9000
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
      - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
      - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
      - ${AIRFLOW_PROJ_DIR:-.}/config:/opt/airflow/config
      - ${AIRFLOW_PROJ_DIR:-.}/src:/opt/airflow/src
      - ${AIRFLOW_PROJ_DIR:-.}/requirements.txt:/opt/airflow/requirements.txt
    command: bash -c "pip install -r /opt/airflow/requirements.txt && airflow celery worker"
    networks:
      - de_network

  airflow_triggerer:
    # image: apache/airflow:2.7.0
    build:
      context: .
      dockerfile: docker/airflow/Dockerfile
    container_name: airflow_triggerer
    restart: always
    depends_on:
      - airflow_webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@de_psql:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@de_psql:5432/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: mysecretkey
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
      - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
      - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
      - ${AIRFLOW_PROJ_DIR:-.}/config:/opt/airflow/config
      - ${AIRFLOW_PROJ_DIR:-.}/src:/opt/airflow/src
      - ${AIRFLOW_PROJ_DIR:-.}/requirements.txt:/opt/airflow/requirements.txt
    command: bash -c "pip install -r /opt/airflow/requirements.txt && airflow triggerer"
    networks:
      - de_network

networks:
  de_network:
    driver: bridge
